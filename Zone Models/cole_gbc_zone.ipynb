{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import dependcies\r\n",
    "import pandas as pd\r\n",
    "from sklearn import tree\r\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\r\n",
    "from sklearn.ensemble import GradientBoostingClassifier\r\n",
    "\r\n",
    "# Create global seed\r\n",
    "yogi = 8"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Read in data \r\n",
    "file_path = '../Data/Pitchers/cole.csv'\r\n",
    "cole_df = pd.read_csv(file_path)\r\n",
    "\r\n",
    "cole_df.dropna(inplace = True)\r\n",
    "\r\n",
    "cole_df.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Drop Unnamed columns\r\n",
    "cole_df.drop(['Unnamed: 0', 'pitch_name'], axis = 1, inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate categorical variable list\r\n",
    "pitch_cat = cole_df.dtypes[cole_df.dtypes == 'object'].index.tolist()\r\n",
    "pitch_cat.remove('player_name')\r\n",
    "pitch_cat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a OneHotEncoder instance\r\n",
    "enc = OneHotEncoder(sparse = False)\r\n",
    "\r\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\r\n",
    "encode_df = pd.DataFrame(enc.fit_transform(cole_df[pitch_cat]))\r\n",
    "\r\n",
    "# Add the encoded varibale names to the DataFrame\r\n",
    "encode_df.columns = enc.get_feature_names(pitch_cat)\r\n",
    "encode_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Merge one-hot encoded features and drop the originals\r\n",
    "cole_df = cole_df.merge(\r\n",
    "    encode_df,\r\n",
    "    left_index = True,\r\n",
    "    right_index = True\r\n",
    ").drop(pitch_cat, 1)\r\n",
    "\r\n",
    "cole_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Drop superfluous columns \r\n",
    "cole_df.drop(columns = ['stand_L'], axis = 1, inplace = True)\r\n",
    "cole_df.head()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compiling, Training, and Testing Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define features set\r\n",
    "X = cole_df.copy()\r\n",
    "X.drop(columns = ['player_name', 'zone', 'balls', 'strikes', 'delta_run_exp', 'delta_home_win_exp'], axis = 1, inplace = True)\r\n",
    "X.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define target vector\r\n",
    "y = cole_df['zone'].values\r\n",
    "y[:5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Split the data into training and testing sets - stratify by pitcher\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = yogi)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a StandardScaler instance\r\n",
    "scaler = StandardScaler()\r\n",
    "\r\n",
    "# Fit Standard Scaler \r\n",
    "X_scaler = scaler.fit(X_train)\r\n",
    "\r\n",
    "# Scaling data\r\n",
    "X_train_scaled = X_scaler.transform(X_train)\r\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Find Best Learning Rate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a classifier object\r\n",
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\r\n",
    "best_rate = 0\r\n",
    "best_acc = 0\r\n",
    "\r\n",
    "for learning_rate in learning_rates:\r\n",
    "    classifier = GradientBoostingClassifier(\r\n",
    "        n_estimators = 20,\r\n",
    "        learning_rate = learning_rate,\r\n",
    "        max_features = 7,\r\n",
    "        max_depth = 4,\r\n",
    "        random_state = yogi)\r\n",
    "    \r\n",
    "    # Fit the model\r\n",
    "    classifier.fit(X_train_scaled, y_train)\r\n",
    "    print(f'Learning Rate: {learning_rate}')\r\n",
    "\r\n",
    "    # Score the model\r\n",
    "    print('Accuracy Score (training): {0:.3f}'.format(\r\n",
    "        classifier.score(\r\n",
    "            X_train_scaled,\r\n",
    "            y_train\r\n",
    "        )\r\n",
    "    ))\r\n",
    "    print('Accuracy Score (validation): {0:.3f}'.format(\r\n",
    "        classifier.score(\r\n",
    "            X_test_scaled,\r\n",
    "            y_test\r\n",
    "        )\r\n",
    "    ))\r\n",
    "    print()\r\n",
    "\r\n",
    "    if classifier.score(X_test_scaled, y_test) > best_acc:\r\n",
    "        best_acc = classifier.score(X_test_scaled, y_test)\r\n",
    "        best_rate = learning_rate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create model with best learning rate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Choose a learning rate and create classifiers\r\n",
    "classifier = GradientBoostingClassifier(\r\n",
    "    n_estimators = 20,\r\n",
    "    learning_rate = best_rate,\r\n",
    "    max_features = 7,\r\n",
    "    max_depth = 3,\r\n",
    "    random_state = yogi\r\n",
    ")\r\n",
    "\r\n",
    "# Fit the model\r\n",
    "classifier.fit(X_train_scaled, y_train)\r\n",
    "\r\n",
    "# Make predictions\r\n",
    "predictions = classifier.predict(X_test_scaled)\r\n",
    "pd.DataFrame({'Prediction': predictions, 'Actual': y_test}).head(20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate accuracy score\r\n",
    "acc_score = accuracy_score(y_test, predictions)\r\n",
    "print(f'Accuracy Score: {acc_score}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate classification report\r\n",
    "print('Classification Report')\r\n",
    "print(classification_report(y_test, predictions))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('mlenv': conda)"
  },
  "interpreter": {
   "hash": "40fb27a0b3552aaaea244cad2a4e2a0b14cdc7fac326086d4f131670520249ee"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}